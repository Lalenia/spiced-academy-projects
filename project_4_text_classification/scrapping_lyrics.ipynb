{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bussiness Goal:\n",
    "\n",
    "Build a text classification model on song lyrics. The task is to predict the artist from a piece of text. To train such a model, you first need to collect your own lyrics dataset:\n",
    "\n",
    "1. Download a HTML page with links to songs.\n",
    "\n",
    "2. Extract hyperlinks of song pages.\n",
    "\n",
    "3. Download and extract the song lyrics.\n",
    "\n",
    "4. Vectorize the text using the Bag Of Words method.\n",
    "\n",
    "5. Train a classification model that predicts the artist from a piece of text.\n",
    "\n",
    "6. Refactor the code into functions.\n",
    "\n",
    "7. Write a simple command-line interface for the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests \n",
    "from requests.exceptions import HTTPError, ConnectionError\n",
    "import re\n",
    "from pathlib import PurePosixPath\n",
    "from urllib.parse import unquote, urlparse\n",
    "import logging\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "_log = logging.getLogger(__name__)\n",
    "\n",
    "CURR_DIR = os.path.abspath('')\n",
    "\n",
    "url_queen = 'https://www.lyrics.com/artist/Queen'\n",
    "url_pixies = 'https://www.lyrics.com/artist/Pixies/5149'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### request_url function.\n",
    "\n",
    "A function for requesting the files was implemented, instead of simply using the one from the Requests module, so as to be able to catch Exceptions often raised when tying to connect with Servers. There are many more exceptions in the Request library, i used here only the basic ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_url(url):\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, verify = False).text\n",
    "    except HTTPError as http_err:\n",
    "        _log.error('HTTP error occurred: {http_err}')\n",
    "    except ConnectionError as con_err:\n",
    "        _log.error('ConnectionError occurred: {con_err_err}')\n",
    "    try:\n",
    "        with open('lyrics_site.html', \"w\", encoding='utf8') as file:\n",
    "            file.write(response)\n",
    "    except IOError as e:\n",
    "        _log.error (\"I/O error({0}): {1}\").format(e.errno, e.strerror)\n",
    "                \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lyrics_url(url):\n",
    "'''Function to request the url for the lyrics site for each individual artist\n",
    "    and with the help of Regular Expression extracts the links -href- for\n",
    "    each song, and saves them to a list'''\n",
    "\n",
    "    url_list = []\n",
    "    resp_text = request_url(url)\n",
    "    url_pattern = 'href=\"/lyric(.+?)\"'\n",
    "    extract_lyrics_url = re.findall(url_pattern, resp_text)\n",
    "    for href in extract_lyrics_url:\n",
    "        conc_url = 'https://www.lyrics.com/lyric' + href\n",
    "        url_list.append(conc_url)\n",
    "    \n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_songs_html(url):\n",
    "'''Given an url with the lyrics site, scrap the every song page of the songs list and \n",
    "extract the lyrics to a text'''\n",
    "\n",
    "    url_list = find_lyrics_url(url)\n",
    "    paths_list = []\n",
    "    for url in url_list[:100]:  \n",
    "        song = requests.get(url, verify = False).text\n",
    "        url_filename = re.findall('([^\\/]+$)', url)\n",
    "        filename = '{0}.txt'.format(url_filename)\n",
    "        path = os.path.join(CURR_DIR + '/' + filename)\n",
    "        if not os.path.isdir(CURR_DIR):\n",
    "            os.makedirs(CURR_DIR)\n",
    "        open(os.path.join(CURR_DIR,filename), 'w', encoding='utf8').write(song)\n",
    "        paths_list.append(path)\n",
    "    return paths_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lyrics_from_html(url):#or function or list of paths\n",
    "'''Given a path to the text song files with HTML content, generate a Dataframe from a list with the artist name, the songs\n",
    "and their lyrics.'''\n",
    "\n",
    "    paths = extract_songs_html(url)\n",
    "    data_lyrics = []\n",
    "    for path in paths:\n",
    "        if path.endswith('txt'):\n",
    "            soup = BeautifulSoup(open(path, encoding=\"utf8\", errors='ignore').read())\n",
    "            artist = soup.find(attrs={'class': 'lyric-artist'}).text.replace('\\nBuy This Song\\n\\n', ' ')\n",
    "            lyric = soup.find(attrs={'class':'lyric-body'}).text\n",
    "            lyrics = re.sub(r'[^\\w]+', ' ', lyric).lower()\n",
    "            data_lyrics.append((lyrics,artist))\n",
    "   \n",
    "    return pd.DataFrame(data_lyrics, columns=['lyrics','artist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_queen = extract_songs_html(url_queen)\n",
    "data_queen = extract_lyrics_from_html(url_queen)\n",
    "data_queen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save the dataframe with pickle, for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data_queen, open('data_queen.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_pixies = extract_songs_html(url_pixies)\n",
    "data_pixies = extract_lyrics_from_html(url_pixies)\n",
    "data_pixies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data_pixies, open('data_pixies.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
