{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "for_the_presentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgzaOvNvgEm-"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import io\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchaudio\n",
        "import tensorflow as tf\n",
        "import torchaudio.transforms as T\n",
        "from torchaudio.datasets import SPEECHCOMMANDS\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import math\n",
        "import tarfile\n",
        "import multiprocessing\n",
        "\n",
        "import numpy as np\n",
        "import pickle\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "import scipy\n",
        "import librosa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHagItnLgU4h",
        "outputId": "35a1bdd3-f90b-437f-df3a-d89732d3fd77"
      },
      "source": [
        "!pip3 install torchaudio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchaudio\n",
            "  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[?25l\r\u001b[K     |▏                               | 10 kB 23.9 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 29.8 MB/s eta 0:00:01\r\u001b[K     |▌                               | 30 kB 33.0 MB/s eta 0:00:01\r\u001b[K     |▊                               | 40 kB 22.5 MB/s eta 0:00:01\r\u001b[K     |▉                               | 51 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |█                               | 61 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 71 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 81 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 92 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 102 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██                              | 112 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██                              | 122 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 133 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 143 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 153 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 163 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 174 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 184 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 194 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 204 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 215 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 225 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████                            | 235 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 245 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 256 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 266 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 276 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 286 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████                           | 296 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 307 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 317 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 327 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 337 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 348 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 358 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 368 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 378 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 389 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 399 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████                         | 409 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████                         | 419 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 430 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 440 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 450 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 460 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████                        | 471 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 481 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 491 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 501 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 512 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 522 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 532 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 542 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 552 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 563 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 573 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 583 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 593 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 604 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 614 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 624 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 634 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 645 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 655 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 665 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 675 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 686 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 696 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 706 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 716 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 727 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 737 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 747 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 757 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 768 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 778 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 788 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 798 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 808 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 819 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 829 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 839 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 849 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 860 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 870 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 880 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 890 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 901 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 911 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 921 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 931 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 942 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 952 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 962 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 972 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 983 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 993 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.0 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.0 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.0 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.0 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.0 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.2 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.2 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.2 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.2 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.2 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.2 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.2 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.2 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.3 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.3 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.3 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.3 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.3 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.3 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.3 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.3 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.3 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.4 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.4 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.4 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.4 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.4 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.4 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.4 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.4 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.4 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.4 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.5 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.5 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.5 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.5 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.5 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.5 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.5 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.5 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.6 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.6 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.6 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.6 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.6 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.6 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.6 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.6 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.6 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.6 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.7 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.7 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.7 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.7 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.7 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.7 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.7 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.7 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.7 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.8 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.8 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.8 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.8 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.8 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.8 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.8 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.8 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.8 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.8 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.9 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.9 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.9 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.9 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.9 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.9 MB 11.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchaudio) (3.7.4.3)\n",
            "Installing collected packages: torchaudio\n",
            "Successfully installed torchaudio-0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywO1h0QBrWr2"
      },
      "source": [
        "# Introduction to PyTorch.\n",
        "## 1. Prepare the data.\n",
        "\n",
        "*  ### Apply transformations on the data.\n",
        "\n",
        "## 2. Define the Network.\n",
        "## 3. Define a Loss function and optimizer.\n",
        "## 4.  Train the network.\n",
        "## 5. Make predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_4cwT5XtRyK"
      },
      "source": [
        "### 1. Prepare the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uj7v7v-6gw6p"
      },
      "source": [
        "import torchaudio\n",
        "from torch.utils.data import Dataset\n",
        "from torch import Tensor\n",
        "from torchaudio.datasets.utils import (\n",
        "    download_url,\n",
        "    extract_archive,\n",
        ")\n",
        "\n",
        "FOLDER_IN_ARCHIVE = \"SpeechCommands\"\n",
        "URL = \"speech_commands_v0.02\"\n",
        "HASH_DIVIDER = \"_nohash_\"\n",
        "EXCEPT_FOLDER = \"_background_noise_\"\n",
        "_CHECKSUMS = {\"https://storage.googleapis.com/download.tensorflow.org/data/speech_commands_v0.01.tar.gz\":\n",
        "    \"3cd23799cb2bbdec517f1cc028f8d43c\",\n",
        "    \"https://storage.googleapis.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz\":\n",
        "    \"6b74f3901214cb2c2934e98196829835\",\n",
        "}\n",
        "\n",
        "class SPEECHCOMMANDS(Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 root: Union[str, Path],\n",
        "                 url= URL,\n",
        "                 folder_in_archive = FOLDER_IN_ARCHIVE,\n",
        "                 download= False,\n",
        "                 subset= None,\n",
        "                 )\n",
        "\n",
        "        if url in [\n",
        "            \"speech_commands_v0.01\",\n",
        "            \"speech_commands_v0.02\",\n",
        "        ]:\n",
        "            base_url = \"https://storage.googleapis.com/download.tensorflow.org/data/\"\n",
        "            ext_archive = \".tar.gz\"\n",
        "\n",
        "            url = os.path.join(base_url, url + ext_archive)\n",
        "\n",
        "        root = os.fspath(root)\n",
        "\n",
        "        basename = os.path.basename(url)\n",
        "        archive = os.path.join(root, basename)\n",
        "\n",
        "        basename = basename.rsplit(\".\", 2)[0]\n",
        "        folder_in_archive = os.path.join(folder_in_archive, basename)\n",
        "\n",
        "        self._path = os.path.join(root, folder_in_archive)\n",
        "\n",
        "        if download:\n",
        "            if not os.path.isdir(self._path):\n",
        "                if not os.path.isfile(archive):\n",
        "                    checksum = _CHECKSUMS.get(url, None)\n",
        "                    download_url(url, root, hash_value=checksum, hash_type=\"md5\")\n",
        "                extract_archive(archive, self._path)\n",
        "\n",
        "        if subset == \"validation\":\n",
        "            self._walker = _load_list(self._path, \"validation_list.txt\")\n",
        "        elif subset == \"testing\":\n",
        "            self._walker = _load_list(self._path, \"testing_list.txt\")\n",
        "        elif subset == \"training\":\n",
        "            excludes = set(_load_list(self._path, \"validation_list.txt\", \"testing_list.txt\"))\n",
        "            walker = sorted(str(p) for p in Path(self._path).glob('*/*.wav'))\n",
        "            self._walker = [\n",
        "                w for w in walker\n",
        "                if HASH_DIVIDER in w\n",
        "                and EXCEPT_FOLDER not in w\n",
        "                and os.path.normpath(w) not in excludes\n",
        "            ]\n",
        "        else:\n",
        "            walker = sorted(str(p) for p in Path(self._path).glob('*/*.wav'))\n",
        "            self._walker = [w for w in walker if HASH_DIVIDER in w and EXCEPT_FOLDER not in w]\n",
        "\n",
        "    def _load_list(root, *filenames):\n",
        "    output = []\n",
        "    for filename in filenames:\n",
        "        filepath = os.path.join(root, filename)\n",
        "        with open(filepath) as fileobj:\n",
        "            output += [os.path.normpath(os.path.join(root, line.strip())) for line in fileobj]\n",
        "    return output\n",
        "\n",
        "    def _load_list(root, *filenames):\n",
        "    output = []\n",
        "    for filename in filenames:\n",
        "        filepath = os.path.join(root, filename)\n",
        "        with open(filepath) as fileobj:\n",
        "            output += [os.path.normpath(os.path.join(root, line.strip())) for line in fileobj]\n",
        "    return output\n",
        "\n",
        "def load_speechcommands_item(filepath, path) -> Tuple[Tensor, int, str, str, int]:\n",
        "    relpath = os.path.relpath(filepath, path)\n",
        "    label, filename = os.path.split(relpath)\n",
        "    speaker, _ = os.path.splitext(filename)\n",
        "    speaker, _ = os.path.splitext(speaker)\n",
        "\n",
        "    speaker_id, utterance_number = speaker.split(HASH_DIVIDER)\n",
        "    utterance_number = int(utterance_number)\n",
        "    #Here resampling\n",
        "\n",
        "    # Load audio\n",
        "    waveform, sample_rate = torchaudio.load(filepath)\n",
        "    return waveform, sample_rate, label, speaker_id, utterance_number\n",
        "\n",
        "    def __getitem__(self, n: int) -> Tuple[Tensor, int, str, str, int]:\n",
        "      fileid = self._walker[n]\n",
        "      return load_speechcommands_item(fileid, self._path)\n",
        "\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self._walker)\n",
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aOwp7CJg3Tb"
      },
      "source": [
        "train_set = SPEECHCOMMANDS(\"training\")\n",
        "test_set = SPEECHCOMMANDS(\"testing\")\n",
        "val_set = SPEECHCOMMANDS(\"validation\")\n",
        "#returns a Tuple with tensors->\n",
        "waveform, sample_rate, label, speaker_id, utterance_number = train_set [0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmSmvbqRg8tY"
      },
      "source": [
        "## Apply transformations on the data.\n",
        "\n",
        "Py Torch Transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcGm07cKhAvA"
      },
      "source": [
        "train_audio_transforms = nn.Sequential(\n",
        "    torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate, n_fft=1024, hop_length=512, n_mels=64),\n",
        "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
        "    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
        ")\n",
        "#Class Text Transform in the project's notebook\n",
        "text_transform = TextTransform()\n",
        "\n",
        "def transform_data(data):\n",
        "  '''Returns melspectograms and lables as 4 dimensional tensors'''\n",
        "   melspectrograms = []\n",
        "   labels = []\n",
        "\n",
        "   for (waveform, sample_rate, label, speaker_id, utterance_number) in data:\n",
        "     waveform = (waveform - waveform.mean()) / waveform.std()\n",
        "     spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "     melspectrograms_.append(spec)\n",
        "     label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
        "     labels.append(label)\n",
        "     melspectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
        "     labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
        "\n",
        "   return melspectrograms, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o6B77DlpIXw"
      },
      "source": [
        "## 2. Define the Network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxIjPtJEoXzv"
      },
      "source": [
        "from torch import nn\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "class CNNNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # 4 conv blocks / flatten / linear / softmax\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=1,\n",
        "                out_channels=16,\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=2\n",
        "            ),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=16,\n",
        "                out_channels=32,\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=2\n",
        "            ),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=32,\n",
        "                out_channels=64,\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=2\n",
        "            ),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=64,\n",
        "                out_channels=128,\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=2\n",
        "            ),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear = nn.Linear(128 * 5 * 4, 10)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        x = self.conv1(input_data)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear(x)\n",
        "        predictions = self.softmax(logits)\n",
        "        return predictions\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    cnn = CNNNetwork()\n",
        "    summary(cnn.cuda(), (1, 64, 44))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9zloXzToZpv"
      },
      "source": [
        "from torchsummary import summary\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class CNNNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn..Conv2d(1, 64, kernel_size=3, padding=1)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=2)\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=2)\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=2)\n",
        "        self.maxpool4 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear = nn.Linear(128 * 5 * 4, 10)\n",
        "        #self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        x = self.conv1(input_data)\n",
        "        x = F.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.maxpool2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.maxpool3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.maxpool4(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.linear(x)\n",
        "        predictions = F.log_softmax(x)\n",
        "        return predictions\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    cnn = CNNNetwork()\n",
        "    summary(cnn.cpu(), (1, 64, 44))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18t1Pvf0tvYY"
      },
      "source": [
        "## 3. Define a Loss function and optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9WW2yhTt_Ez"
      },
      "source": [
        "loss_fn = nn.CTCLoss(blank=28).to(device)\n",
        "optimiser = torch.optim.Adam(cnn.parameters(),lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy8aZIP2pAq9"
      },
      "source": [
        "##4. Train the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z0tFEDTolgc"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#Here i can use the RayTune hyperparameters.\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "\n",
        "#def create_data_loader(train_data, batch_size):\n",
        " #   train_dataloader = DataLoader(train_data, batch_size)\n",
        "  #  return train_dataloader\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(dataset=train_data, \n",
        "                                                batch_size = BATCH_SIZE, \n",
        "                                                collate_fn=lambda x: transform_data(x)\n",
        "\n",
        "def train_single_epoch(model, train_dataloader, loss_fn, optimiser, device):\n",
        "\n",
        "  for batch_idx, data in enumerate(data_loader):\n",
        "    input , target = transform_data(data)\n",
        "    input, target = input.to(device), target.to(device)\n",
        "\n",
        "    prediction = model(input)\n",
        "    loss = loss_fn(prediction, target)\n",
        "\n",
        "    optimiser.zero_grad()\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "\n",
        "\n",
        "def train(model, train_dataloader, loss_fn, optimiser, device, epochs, batch_size):\n",
        "    for i in range(epochs):\n",
        "        print(f\"Epoch {i+1}\")\n",
        "        train_single_epoch(model, train_dataloader, loss_fn, optimiser, device)\n",
        "        print(\"---------------------------\")\n",
        "    print(\"Finished training\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "    device = \"cpu\"\n",
        "  print(f\"Using {device}\")\n",
        "\n",
        "    train_data = DataSplitter(\"training\")\n",
        "    test_data = DataSplitter(\"testing\")\n",
        "    val_data = DataSplitter(\"validation\")\n",
        "    \n",
        "    #train_dataloader = create_data_loader(train_set, BATCH_SIZE)\n",
        "\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(dataset=train_data, \n",
        "                                                   batch_size = BATCH_SIZE, \n",
        "                                                   collate_fn=lambda x: transform_data(x)\n",
        "\n",
        "    # construct model and assign it to device\n",
        "    cnn = CNNNetwork().to(device)\n",
        "    print(cnn)\n",
        "\n",
        "    # initialise loss funtion + optimiser\n",
        "    loss_fn = nn.CTCLoss(blank=28).to(device)\n",
        "    optimiser = torch.optim.Adam(cnn.parameters(),\n",
        "                                 lr=LEARNING_RATE)\n",
        "\n",
        "    # train model\n",
        "    train(cnn, train_dataloader, loss_fn, optimiser, device, EPOCHS)\n",
        "\n",
        "    # save model\n",
        "    torch.save(cnn.state_dict(), \"feedforwardnet.pth\")\n",
        "    print(\"Trained feed forward net saved at feedforwardnet.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwJudXZiupf0"
      },
      "source": [
        "##5. Make predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4rPqm2RuhWZ"
      },
      "source": [
        "class_mapping = ['backward',\n",
        " 'bed',\n",
        " 'bird',\n",
        " 'cat',\n",
        " 'dog',\n",
        " 'down',\n",
        " 'eight',\n",
        " 'five',\n",
        " 'follow',\n",
        " 'forward',\n",
        " 'four',\n",
        " 'go',\n",
        " 'happy',\n",
        " 'house',\n",
        " 'learn',\n",
        " 'left',\n",
        " 'marvin',\n",
        " 'nine',\n",
        " 'no',\n",
        " 'off',\n",
        " 'on',\n",
        " 'one',\n",
        " 'right',\n",
        " 'seven',\n",
        " 'sheila',\n",
        " 'six',\n",
        " 'stop',\n",
        " 'three',\n",
        " 'tree',\n",
        " 'two',\n",
        " 'up',\n",
        " 'visual',\n",
        " 'wow',\n",
        " 'yes',\n",
        " 'zero']\n",
        "\n",
        "\n",
        "def predict(model, input, target, class_mapping):\n",
        "    model.eval()\n",
        "    #\n",
        "    with torch.no_grad():\n",
        "      #This function here :Context-manager that disabled gradient calculation is disabling gradient calculation is useful for inference, when you are sure that you will not call Tensor.backward(). \n",
        "      #It will reduce memory consumption for computations that would otherwise have requires_grad=True.\n",
        "\n",
        "        predictions = model(input)\n",
        "        predicted_index = predictions[0].argmax(0)\n",
        "        predicted = class_mapping[predicted_index]\n",
        "        expected = class_mapping[target]\n",
        "    return predicted, expected\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # load back the model\n",
        "    cnn = CNNNetwork()\n",
        "    state_dict = torch.load(\"cnnnet.pth\")\n",
        "    cnn.load_state_dict(state_dict)\n",
        "\n",
        "    # get a sample from the SpeechCommands Dataset\n",
        "    input, target = test_set[0][0], test_set[0][1] # [batch size, waveform, sample_rate etc]\n",
        "    input.unsqueeze_(0)\n",
        "\n",
        "    # make an inference\n",
        "    predicted, expected = predict(cnn, input, target,\n",
        "                                  class_mapping)\n",
        "    print(f\"Predicted: '{predicted}', expected: '{expected}'\")\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyL5Q36b2VHf"
      },
      "source": [
        "Plus features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37Rf1Lpmx9ac"
      },
      "source": [
        "view() , reshape()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}