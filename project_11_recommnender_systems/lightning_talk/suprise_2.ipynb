{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9305  0.9335  0.9372  0.9433  0.9317  0.9352  0.0046  \n",
      "MAE (testset)     0.7357  0.7355  0.7370  0.7423  0.7357  0.7372  0.0026  \n",
      "Fit time          6.05    5.93    6.29    6.55    7.81    6.52    0.67    \n",
      "Test time         0.28    0.21    0.28    0.22    0.20    0.24    0.03    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.93051888, 0.93354405, 0.93716221, 0.94333692, 0.93167682]),\n",
       " 'test_mae': array([0.73566134, 0.73550649, 0.73703595, 0.74230855, 0.73565443]),\n",
       " 'fit_time': (6.053062200546265,\n",
       "  5.927455902099609,\n",
       "  6.2852678298950195,\n",
       "  6.547177076339722,\n",
       "  7.805340051651001),\n",
       " 'test_time': (0.2803990840911865,\n",
       "  0.21345996856689453,\n",
       "  0.2801809310913086,\n",
       "  0.216141939163208,\n",
       "  0.2032921314239502)}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "#Matrix Factorization Algorithms\n",
    "from surprise import SVD\n",
    "from surprise import NMF\n",
    "\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "##CrossValidation\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "\n",
    "\n",
    "# Load the movielens-100k dataset (download it if needed),\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Run 5-fold cross-validation and print results\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : Here explain SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9434142435260771"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Load the movielens-100k dataset (download it if needed),\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "# sample random trainset and testset\n",
    "# test set is made of 25% of the ratings.\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Then compute RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can train and test an algorithm with the following one-line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = algo.fit(trainset).test(testset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on a whole trainset and the predict() method\n",
    "\n",
    "Obviously, we could also simply fit our algorithm to the whole dataset, rather than running cross-validation. This can be done by using the build_full_trainset() method which will build a trainset object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x7fae7b682610>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import KNNBasic\n",
    "from surprise import Dataset\n",
    "\n",
    "# Load the movielens-100k dataset\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "# Retrieve the trainset.\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "# Build an algorithm, and train it.\n",
    "algo = KNNBasic()\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now predict ratings by directly calling the predict() method. Let‚Äôs say you‚Äôre interested in user 196 and item 302 (make sure they‚Äôre in the trainset!), and you know that the true rating ùëüùë¢ùëñ=4:\n",
    "\n",
    "Note : explain raw here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 196        item: 302        r_ui = 4.00   est = 4.06   {'actual_k': 40, 'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "uid = str(196)  # raw user id (as in the ratings file). They are **strings**!\n",
    "iid = str(302)  # raw item id (as in the ratings file). They are **strings**!\n",
    "\n",
    "# get a prediction for specific users and items.\n",
    "pred = algo.predict(uid, iid, r_ui=4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Evaluating RMSE, MAE of algorithm BaselineOnly on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9491  0.9395  0.9472  0.9451  0.9400  0.9442  0.0038  \n",
      "MAE (testset)     0.7538  0.7433  0.7495  0.7511  0.7449  0.7485  0.0039  \n",
      "Fit time          0.23    0.25    0.25    0.27    0.25    0.25    0.01    \n",
      "Test time         0.12    0.13    0.18    0.19    0.12    0.15    0.03    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.94913132, 0.93947681, 0.94715078, 0.94507213, 0.93997431]),\n",
       " 'test_mae': array([0.75375807, 0.74328229, 0.74950678, 0.75109599, 0.74490864]),\n",
       " 'fit_time': (0.23137831687927246,\n",
       "  0.252230167388916,\n",
       "  0.24802803993225098,\n",
       "  0.26909422874450684,\n",
       "  0.2515430450439453),\n",
       " 'test_time': (0.12460207939147949,\n",
       "  0.12652277946472168,\n",
       "  0.18208789825439453,\n",
       "  0.1868448257446289,\n",
       "  0.12173223495483398)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import BaselineOnly\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "import os\n",
    "\n",
    "# path to dataset file\n",
    "file_path = os.path.expanduser('~/.surprise_data/ml-100k/ml-100k/u.data')\n",
    "\n",
    "# As we're loading a custom dataset, we need to define a reader. In the\n",
    "# movielens-100k dataset, each line has the following format:\n",
    "# 'user item rating timestamp', separated by '\\t' characters.\n",
    "reader = Reader(line_format='user item rating timestamp', sep='\\t')\n",
    "\n",
    "data = Dataset.load_from_file(file_path, reader=reader)\n",
    "\n",
    "# We can now use this dataset as we please, e.g. calling cross_validate\n",
    "cross_validate(BaselineOnly(), data, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Or use a csv file as we did for our project!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.42500869, 1.41873179]),\n",
       " 'test_mae': array([1.13844198, 1.1330959 ]),\n",
       " 'fit_time': (0.09530019760131836, 0.09567999839782715),\n",
       " 'test_time': (0.573645830154419, 0.5580999851226807)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from surprise import NormalPredictor\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "\n",
    "# Creation of the dataframe. Column names are irrelevant.\n",
    "ratings_dict = {'itemID': [1, 1, 1, 2, 2],\n",
    "                'userID': [9, 32, 2, 45, 'user_foo'],\n",
    "                'rating': [3, 2, 4, 3, 1]}\n",
    "df = pd.DataFrame(ratings_dict)\n",
    "\n",
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data_ = Dataset.load_from_df(df[['userID', 'itemID', 'rating']], reader)\n",
    "\n",
    "#Or USE  the movieLensDataset\n",
    "ratings = pd.read_csv('/Users/test1/Desktop/week_11/data/ratings.csv')\n",
    "data =Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "\n",
    "# We can now use this dataset as we please, e.g. calling cross_validate\n",
    "cross_validate(NormalPredictor(), data, cv=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: explain here for cross-validation iterators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9449\n",
      "RMSE: 0.9458\n",
      "RMSE: 0.9464\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import KFold\n",
    "\n",
    "# Load the movielens-100k dataset\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "# define a cross-validation iterator\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "algo = SVD()\n",
    "\n",
    "for trainset, testset in kf.split(data):\n",
    "\n",
    "    # train and test algorithm.\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "    # Compute and print Root Mean Squared Error\n",
    "    accuracy.rmse(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9517\n",
      "RMSE: 0.9397\n",
      "RMSE: 0.9350\n",
      "RMSE: 0.9321\n",
      "RMSE: 0.9328\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import PredefinedKFold\n",
    "\n",
    "# path to dataset folder\n",
    "files_dir = os.path.expanduser('~/.surprise_data/ml-100k/ml-100k/')\n",
    "\n",
    "# This time, we'll use the built-in reader.\n",
    "reader = Reader('ml-100k')\n",
    "\n",
    "# folds_files is a list of tuples containing file paths:\n",
    "# [(u1.base, u1.test), (u2.base, u2.test), ... (u5.base, u5.test)]\n",
    "train_file = files_dir + 'u%d.base'\n",
    "test_file = files_dir + 'u%d.test'\n",
    "folds_files = [(train_file % i, test_file % i) for i in (1, 2, 3, 4, 5)]\n",
    "\n",
    "data = Dataset.load_from_folds(folds_files, reader=reader)\n",
    "pkf = PredefinedKFold()\n",
    "\n",
    "algo = SVD()\n",
    "\n",
    "for trainset, testset in pkf.split(data):\n",
    "\n",
    "    # train and test algorithm.\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "    # Compute and print Root Mean Squared Error\n",
    "    accuracy.rmse(predictions, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note explain here how to tune algorithm parameters with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9646314857211871\n",
      "{'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.4}\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# Use movielens-100K\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "param_grid = {'n_epochs': [5, 10], 'lr_all': [0.002, 0.005],\n",
    "              'reg_all': [0.4, 0.6]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:\n",
    "0.961300130118\n",
    "{'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.4}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7fae81540a90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now use the algorithm that yields the best rmse:\n",
    "algo = gs.best_estimator['rmse']\n",
    "algo.fit(data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A bit advanced here. Needs explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary parameters such as bsl_options and sim_options require particular treatment. See usage example below:\n",
    "param_grid = {'k': [10, 20],\n",
    "              'sim_options': {'name': ['msd', 'cosine'],\n",
    "                              'min_support': [1, 5],\n",
    "                              'user_based': [False]}\n",
    "              }\n",
    "\n",
    "#Naturally, both can be combined, for example for the KNNBaseline algorithm:\n",
    "param_grid = {'bsl_options': {'method': ['als', 'sgd'],\n",
    "                              'reg': [1, 2]},\n",
    "              'k': [2, 3],\n",
    "              'sim_options': {'name': ['msd', 'cosine'],\n",
    "                              'min_support': [1, 5],\n",
    "                              'user_based': [False]}\n",
    "              }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further analysis, the cv_results attribute has all the needed information and can be imported in a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_dict(gs.cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'split0_test_rmse': [1.0, 1.0, 0.97, 0.98, 0.98, 0.99, 0.96, 0.97]\n",
    "'split1_test_rmse': [1.0, 1.0, 0.97, 0.98, 0.98, 0.99, 0.96, 0.97]\n",
    "'split2_test_rmse': [1.0, 1.0, 0.97, 0.98, 0.98, 0.99, 0.96, 0.97]\n",
    "'mean_test_rmse':   [1.0, 1.0, 0.97, 0.98, 0.98, 0.99, 0.96, 0.97]\n",
    "'std_test_rmse':    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "'rank_test_rmse':   [7 8 3 5 4 6 1 2]\n",
    "'split0_test_mae':  [0.81, 0.82, 0.78, 0.79, 0.79, 0.8, 0.77, 0.79]\n",
    "'split1_test_mae':  [0.8, 0.81, 0.78, 0.79, 0.78, 0.79, 0.77, 0.78]\n",
    "'split2_test_mae':  [0.81, 0.81, 0.78, 0.79, 0.78, 0.8, 0.77, 0.78]\n",
    "'mean_test_mae':    [0.81, 0.81, 0.78, 0.79, 0.79, 0.8, 0.77, 0.78]\n",
    "'std_test_mae':     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "'rank_test_mae':    [7 8 2 5 4 6 1 3]\n",
    "'mean_fit_time':    [1.53, 1.52, 1.53, 1.53, 3.04, 3.05, 3.06, 3.02]\n",
    "'std_fit_time':     [0.03, 0.04, 0.0, 0.01, 0.04, 0.01, 0.06, 0.01]\n",
    "'mean_test_time':   [0.46, 0.45, 0.44, 0.44, 0.47, 0.49, 0.46, 0.34]\n",
    "'std_test_time':    [0.0, 0.01, 0.01, 0.0, 0.03, 0.06, 0.01, 0.08]\n",
    "'params':           [{'n_epochs': 5, 'lr_all': 0.002, 'reg_all': 0.4}, {'n_epochs': 5, 'lr_all': 0.002, 'reg_all': 0.6}, {'n_epochs': 5, 'lr_all': 0.005, 'reg_all': 0.4}, {'n_epochs': 5, 'lr_all': 0.005, 'reg_all': 0.6}, {'n_epochs': 10, 'lr_all': 0.002, 'reg_all': 0.4}, {'n_epochs': 10, 'lr_all': 0.002, 'reg_all': 0.6}, {'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.4}, {'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.6}]\n",
    "'param_n_epochs':   [5, 5, 5, 5, 10, 10, 10, 10]\n",
    "'param_lr_all':     [0.0, 0.0, 0.01, 0.01, 0.0, 0.0, 0.01, 0.01]\n",
    "'param_reg_all':    [0.4, 0.6, 0.4, 0.6, 0.4, 0.6, 0.4, 0.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Command line usage\n",
    "\n",
    "Surprise can also be used from the command line, for example:\n",
    "\n",
    "Note: try it at terminal.\n",
    "\n",
    "\n",
    "surprise -algo SVD -params \"{'n_epochs': 5, 'verbose': True}\" -load-builtin ml-100k -n-folds 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Literature:\n",
    "\n",
    " https://surprise.readthedocs.io/en/stable/matrix_factorization.html\n",
    " https://surprise.readthedocs.io/en/stable/getting_started.html#load-from-folds-example\n",
    " https://towardsdatascience.com/simple-svd-algorithms-13291ad2eef2\n",
    " https://medium.com/swlh/eigenvalues-and-eigenvectors-5fbc8b037eed\n",
    " https://surprise.readthedocs.io/en/stable/prediction_algorithms.html#prediction-algorithms\n",
    " http://surpriselib.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
